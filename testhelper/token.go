package testhelper

import (
	"testing"

	"github.com/ndabAP/entitydebs/tokenize"
)

func NewExampleTokens1(t *testing.T, charOffset, depOffset int32) []*tokenize.Token {
	t.Helper()

	return []*tokenize.Token{
		NewToken(t,
			"I",
			0+charOffset,
			NewPoS(t,
				tokenize.PartOfSpeechTagNoun,
				PoSParams{
					Tag:    tokenize.PartOfSpeechTagNoun,
					Case:   tokenize.PartOfSpeechCaseNominative,
					Number: tokenize.PartOfSpeechNumberSingular,
					Person: tokenize.PartOfSpeechPersonFirst,
				},
			),
			NewDepEdge(t,
				1+depOffset,
				tokenize.DependencyEdgeLabelNSubj,
			),
			"I",
		),
		NewToken(t,
			"prefer",
			2+charOffset,
			NewPoS(t,
				tokenize.PartOfSpeechTagVerb,
				PoSParams{
					Tag:   tokenize.PartOfSpeechTagVerb,
					Mood:  tokenize.PartOfSpeechMoodIndicative,
					Tense: tokenize.PartOfSpeechTensePresent,
				},
			),
			NewDepEdge(t,
				1+depOffset,
				tokenize.DependencyEdgeLabelRoot,
			),
			"prefer",
		),
		NewToken(t,
			"the",
			9+charOffset,
			NewPoS(t,
				tokenize.PartOfSpeechTagDet,
				PoSParams{},
			),
			NewDepEdge(t,
				4+depOffset,
				tokenize.DependencyEdgeLabelDet,
			),
			"the",
		),
		NewToken(t,
			"morning",
			13+charOffset,
			NewPoS(t,
				tokenize.PartOfSpeechTagNoun,
				PoSParams{
					Number: tokenize.PartOfSpeechNumberSingular,
				},
			),
			NewDepEdge(t,
				4+depOffset,
				tokenize.DependencyEdgeLabelNN,
			),
			"morning",
		),
		NewToken(t,
			"flight",
			21+charOffset,
			NewPoS(t,
				tokenize.PartOfSpeechTagNoun,
				PoSParams{
					Number: tokenize.PartOfSpeechNumberSingular,
				},
			),
			NewDepEdge(t,
				1+depOffset,
				tokenize.DependencyEdgeLabelDObj,
			),
			"flight",
		),
		NewToken(t,
			"through",
			28+charOffset,
			NewPoS(t,
				tokenize.PartOfSpeechTagAdp,
				PoSParams{},
			),
			NewDepEdge(t,
				4+depOffset,
				tokenize.DependencyEdgeLabelPrep,
			),
			"through",
		),
		NewToken(t,
			"Denver",
			36+charOffset,
			NewPoS(t,
				tokenize.PartOfSpeechTagNoun,
				PoSParams{
					Number: tokenize.PartOfSpeechNumberSingular,
					Proper: tokenize.PartOfSpeechIsProper,
				},
			),
			NewDepEdge(t,
				5+depOffset,
				tokenize.DependencyEdgeLabelPObj,
			),
			"Denver",
		),
		NewToken(t,
			".",
			42+charOffset,
			NewPoS(
				t,
				tokenize.PartOfSpeechTagPunct,
				PoSParams{},
			),
			NewDepEdge(t,
				1+depOffset,
				tokenize.DependencyEdgeLabelP,
			),
			".",
		),
	}
}

func NewExampleTokens2(t *testing.T, charOffset, depOffset int32) []*tokenize.Token {
	t.Helper()

	return []*tokenize.Token{
		NewToken(t,
			"Book",
			0+charOffset,
			NewPoS(t,
				tokenize.PartOfSpeechTagVerb,
				PoSParams{
					Tag: tokenize.PartOfSpeechTagVerb,
				},
			),
			NewDepEdge(t,
				0+depOffset,
				tokenize.DependencyEdgeLabelRoot,
			),
			"Book",
		),
		NewToken(t,
			"me",
			5+charOffset,
			NewPoS(t,
				tokenize.PartOfSpeechTagPron,
				PoSParams{
					Tag:    tokenize.PartOfSpeechTagPron,
					Case:   tokenize.PartOfSpeechCaseAccusative,
					Number: tokenize.PartOfSpeechNumberSingular,
					Person: tokenize.PartOfSpeechPersonFirst,
				},
			),
			NewDepEdge(t,
				0+depOffset,
				tokenize.DependencyEdgeLabelIObj,
			),
			"me",
		),
		NewToken(t,
			"the",
			8+charOffset,
			NewPoS(t,
				tokenize.PartOfSpeechTagDet,
				PoSParams{
					Tag: tokenize.PartOfSpeechTagDet,
				},
			),
			NewDepEdge(t,
				3+depOffset,
				tokenize.DependencyEdgeLabelDet,
			),
			"the",
		),
		NewToken(t,
			"flight",
			12+charOffset,
			NewPoS(t,
				tokenize.PartOfSpeechTagNoun,
				PoSParams{
					Tag:    tokenize.PartOfSpeechTagNoun,
					Number: tokenize.PartOfSpeechNumberSingular,
				},
			),
			NewDepEdge(t,
				0+depOffset,
				tokenize.DependencyEdgeLabelDObj,
			),
			"flight",
		),
		NewToken(t,
			"through",
			19+charOffset,
			NewPoS(t,
				tokenize.PartOfSpeechTagAdp,
				PoSParams{
					Tag: tokenize.PartOfSpeechTagAdp,
				},
			),
			NewDepEdge(t,
				3+depOffset,
				tokenize.DependencyEdgeLabelPrep,
			),
			"through",
		),
		NewToken(t,
			"Houston",
			27+charOffset,
			NewPoS(t,
				tokenize.PartOfSpeechTagNoun,
				PoSParams{
					Tag:    tokenize.PartOfSpeechTagNoun,
					Number: tokenize.PartOfSpeechNumberSingular,
					Proper: tokenize.PartOfSpeechIsProper,
				},
			),
			NewDepEdge(t,
				4+depOffset,
				tokenize.DependencyEdgeLabelPObj,
			),
			"Houston",
		),
		NewToken(t,
			".",
			34+charOffset,
			NewPoS(t,
				tokenize.PartOfSpeechTagPunct,
				PoSParams{},
			),
			NewDepEdge(t,
				0+depOffset,
				tokenize.DependencyEdgeLabelP,
			),
			".",
		),
	}
}
